{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nihimlEhW-DV"
   },
   "source": [
    "# Ожидаемые результаты\n",
    "\n",
    "(демонстрационная версия) -это работающая пилотная система с удобным для тестирования интерфейсом (в виде ipynb ноутбука с моделями и разработанным алгоритмом, пилотного консольного, десктопного либо веб-приложения), обеспечивающая проверку работоспособности и функциональность технологий и решений, а также позволяющая сделать оценку необходимой аппаратной конфигурации серверной части разрабатываемой системы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0thCbl-Wabb"
   },
   "source": [
    "## Визуализация снимок\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qfI-LJYJZdq"
   },
   "source": [
    "```python\n",
    "%%time\n",
    "# Run inference on an image\n",
    "results = model(image)  # results list\n",
    "\n",
    "# Visualize the results\n",
    "for i, r in enumerate(results):\n",
    "    r.names = mn\n",
    "    # Plot results image\n",
    "    im_bgr = r.plot(line_width=1, font_size=11, labels=True, conf=False)  # BGR-order numpy array\n",
    "    im_rgb = im_bgr[..., ::-1]  # Convert BGR to RGB\n",
    "\n",
    "    # Display using Matplotlib\n",
    "    plt.figure()\n",
    "    plt.imshow(im_rgb)\n",
    "    plt.imsave('result.jpg',im_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print(results)\n",
    "```\n",
    "```\n",
    "[ultralytics.engine.results.Results object with attributes:\n",
    "\n",
    " boxes: ultralytics.engine.results.Boxes object\n",
    " keypoints: None\n",
    " masks: None\n",
    " names: {0: '', 1: '', 2: '', 3: '', 4: 'Нарушение', 5: 'Нарушение', 6: 'Нарушение', 7: 'Нарушение', 8: 'Нарушение', 9: ''}\n",
    " obb: None\n",
    " orig_img: array([[[ 79,  29,  11],\n",
    "         [ 78,  28,  10],\n",
    "         [ 79,  29,  11],\n",
    "         ...,\n",
    "         [  5,  21,  28],\n",
    "         [  4,  20,  27],\n",
    "         [  4,  20,  27]],\n",
    "\n",
    "        [[ 82,  32,  14],\n",
    "         [ 85,  35,  17],\n",
    "         [ 89,  39,  21],\n",
    "         ...,\n",
    "         [ 11,  27,  34],\n",
    "         [ 11,  27,  34],\n",
    "         [ 10,  26,  33]],\n",
    "\n",
    "        [[ 89,  39,  21],\n",
    "         [ 94,  44,  26],\n",
    "         [100,  50,  30],\n",
    "         ...,\n",
    "         [ 12,  28,  34],\n",
    "         [ 12,  28,  34],\n",
    "         [ 12,  28,  34]],\n",
    "\n",
    "        ...,\n",
    "\n",
    "        [[ 79,  96,  82],\n",
    "         [ 46,  63,  49],\n",
    "         [ 30,  47,  34],\n",
    "         ...,\n",
    "         [116, 107, 103],\n",
    "         [122, 113, 109],\n",
    "         [120, 111, 107]],\n",
    "\n",
    "        [[100, 119, 104],\n",
    "         [ 76,  95,  80],\n",
    "         [ 60,  78,  65],\n",
    "         ...,\n",
    "         [116, 107, 103],\n",
    "         [123, 112, 108],\n",
    "         [121, 110, 106]],\n",
    "\n",
    "        [[109, 130, 115],\n",
    "         [ 81, 102,  87],\n",
    "         [ 75,  93,  80],\n",
    "         ...,\n",
    "         [117, 108, 104],\n",
    "         [124, 113, 109],\n",
    "         [121, 110, 106]]], dtype=uint8)\n",
    " orig_shape: (1280, 1280)\n",
    " path: '/content/drive/MyDrive/datasets/shod-heavy/test.jpg'\n",
    " probs: None\n",
    " save_dir: 'runs/detect/predict'\n",
    " speed: {'preprocess': 31.212329864501953, 'inference': 161.69023513793945, 'postprocess': 8055.536985397339}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pizUGe3LOTo"
   },
   "source": [
    "## Визуализация видео"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nw4VcjepKeIC"
   },
   "source": [
    "```python\n",
    "%%time\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# Open the video file\n",
    "video_path = video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get the total number of frames in the video\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Total frames in the video:\", total_frames)\n",
    "\n",
    "# Set the start frame\n",
    "start_frame = 0\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# Set the last frame\n",
    "last_frame = 510\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "\n",
    "        # Break the loop if the current frame exceeds the last frame\n",
    "        if cap.get(cv2.CAP_PROP_POS_FRAMES) > last_frame: break\n",
    "\n",
    "        if cap.get(cv2.CAP_PROP_POS_FRAMES) in [1]:\n",
    "\n",
    "          # Run YOLOv8 inference on the frame\n",
    "          results = model(frame)\n",
    "\n",
    "          results = results[0]\n",
    "          results.names = mn\n",
    "\n",
    "          #plt.imsave('/content/drive/MyDrive/datasets/shod-heavy/test/{0}_frame.jpg'.format(int(cap.get(cv2.CAP_PROP_POS_FRAMES))),frame[..., ::-1])\n",
    "\n",
    "          # Visualize the results on the frame\n",
    "          annotated_frame = results.plot(line_width=3, font_size=22, labels=True, conf=False)\n",
    "\n",
    "          #plt.imsave('/content/drive/MyDrive/datasets/shod-heavy/test/result_{0}_frame.jpg'.format(int(cap.get(cv2.CAP_PROP_POS_FRAMES))),annotated_frame[..., ::-1])\n",
    "\n",
    "          # Display the annotated frame\n",
    "          #cv2_imshow(annotated_frame)\n",
    "\n",
    "          # Break the loop if 'q' is pressed\n",
    "          if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "              break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "#cap.release()\n",
    "#cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "```\n",
    "Total frames in the video: 584\n",
    "\n",
    "WARNING ⚠️ NMS time limit 2.050s exceeded\n",
    "0: 960x1280 2 Каскаs, 4 Перчаткаs, 3 Обувьs, 3 Одеждаs, 2 Каска. Нарушениеs, 1 Обувью Нарушение, 1 Одежда. Нарушение, 4 Рабочиеs, 269.0ms\n",
    "Speed: 43.2ms preprocess, 269.0ms inference, 7756.9ms postprocess per image at shape (1, 3, 960, 1280)\n",
    "Downloading https://ultralytics.com/assets/Arial.Unicode.ttf to '/root/.config/Ultralytics/Arial.Unicode.ttf'...\n",
    "100%|██████████| 22.2M/22.2M [00:00<00:00, 204MB/s]\n",
    "\n",
    "0: 960x1280 2 Каскаs, 4 Перчаткаs, 3 Обувьs, 3 Одеждаs, 2 Каска. Нарушениеs, 1 Обувью Нарушение, 1 Одежда. Нарушение, 4 Рабочиеs, 126.2ms\n",
    "Speed: 11.7ms preprocess, 126.2ms inference, 1.5ms postprocess per image at shape (1, 3, 960, 1280)\n",
    "\n",
    "0: 960x1280 1 Каска, 3 Перчаткаs, 2 Обувьs, 2 Одеждаs, 2 Каска. Нарушениеs, 1 Обувью Нарушение, 1 Одежда. Нарушение, 3 Рабочиеs, 88.9ms\n",
    "Speed: 11.1ms preprocess, 88.9ms inference, 1.8ms postprocess per image at shape (1, 3, 960, 1280)\n",
    "\n",
    "0: 960x1280 1 Каска, 2 Перчаткаs, 1 Обувь, 3 Одеждаs, 3 Каска. Нарушениеs, 1 Обувью Нарушение, 1 Одежда. Нарушение, 4 Рабочиеs, 126.2ms\n",
    "Speed: 10.9ms preprocess, 126.2ms inference, 1.6ms postprocess per image at shape (1, 3, 960, 1280)\n",
    "\n",
    "0: 960x1280 1 Каска, 1 Перчатка, 2 Обувьs, 3 Одеждаs, 4 Каска. Нарушениеs, 1 Обувью Нарушение, 2 Одежда. Нарушениеs, 5 Рабочиеs, 125.3ms\n",
    "Speed: 10.6ms preprocess, 125.3ms inference, 1.6ms postprocess per image at shape (1, 3, 960, 1280)\n",
    "\n",
    "0: 960x1280 1 Каска, 1 Перчатка, 1 Обувь, 3 Одеждаs, 1 Курение, 4 Каска. Нарушениеs, 1 Обувью Нарушение, 2 Одежда. Нарушениеs, 5 Рабочиеs, 123.7ms\n",
    "Speed: 11.0ms preprocess, 123.7ms inference, 2.3ms postprocess per image at shape (1, 3, 960, 1280)\n",
    "CPU times: user 18.9 s, sys: 988 ms, total: 19.9 s\n",
    "Wall time: 24.2 s\n",
    "```\n",
    "\n",
    "```python\n",
    "results[0]\n",
    "```\n",
    "```\n",
    "ultralytics.engine.results.Results object with attributes:\n",
    "\n",
    "boxes: ultralytics.engine.results.Boxes object\n",
    "keypoints: None\n",
    "masks: None\n",
    "names: {0: '', 1: '', 2: '', 3: '', 4: 'Нарушение', 5: 'Нарушение', 6: 'Нарушение', 7: 'Нарушение', 8: 'Нарушение', 9: ''}\n",
    "obb: None\n",
    "orig_img: array([[[ 50,  22,   9],\n",
    "        [ 50,  22,   9],\n",
    "        [ 50,  22,   9],\n",
    "        ...,\n",
    "        [125,  96,  72],\n",
    "        [125,  96,  72],\n",
    "        [125,  96,  72]],\n",
    "\n",
    "       [[ 53,  25,  12],\n",
    "        [ 53,  25,  12],\n",
    "        [ 53,  25,  12],\n",
    "        ...,\n",
    "        [133, 104,  80],\n",
    "        [133, 104,  80],\n",
    "        [133, 104,  80]],\n",
    "\n",
    "       [[ 59,  31,  18],\n",
    "        [ 59,  31,  18],\n",
    "        [ 59,  31,  18],\n",
    "        ...,\n",
    "        [142, 113,  89],\n",
    "        [142, 113,  89],\n",
    "        [142, 113,  89]],\n",
    "\n",
    "       ...,\n",
    "\n",
    "       [[ 54,  95,  68],\n",
    "        [ 58,  99,  72],\n",
    "        [ 49,  90,  63],\n",
    "        ...,\n",
    "        [ 99,  98,  87],\n",
    "        [ 88,  84,  74],\n",
    "        [ 84,  80,  70]],\n",
    "\n",
    "       [[113, 171, 141],\n",
    "        [ 88, 146, 116],\n",
    "        [ 51, 104,  75],\n",
    "        ...,\n",
    "        [ 97,  93,  83],\n",
    "        [ 91,  85,  75],\n",
    "        [ 89,  83,  73]],\n",
    "\n",
    "       [[159, 217, 187],\n",
    "        [108, 166, 136],\n",
    "        [ 42,  95,  66],\n",
    "        ...,\n",
    "        [ 95,  91,  81],\n",
    "        [ 94,  88,  78],\n",
    "        [ 93,  87,  77]]], dtype=uint8)\n",
    "orig_shape: (1944, 2592)\n",
    "path: 'image0.jpg'\n",
    "probs: None\n",
    "save_dir: None\n",
    "speed: {'preprocess': None, 'inference': None, 'postprocess': None}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-s1vP1ILY2G"
   },
   "source": [
    "## Код detection.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZB1SNWVat22E"
   },
   "source": [
    "```python\n",
    "%%writefile detection.py\n",
    "# !pip -q install ultralytics\n",
    "# !pip -q install ffmpeg-python\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import ffmpeg\n",
    "import datetime\n",
    "\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from datetime import timedelta\n",
    "from collections import Counter\n",
    "\n",
    "# Load a pretrained YOLOv8n model\n",
    "model = YOLO('best.pt')\n",
    "# новые названия классов\n",
    "mn = {0: 'Каска',\n",
    " 1: 'Перчатки',\n",
    " 2: 'Обувь',\n",
    " 3: 'Одежда',\n",
    " 4: 'Курение',\n",
    " 5: 'Каска. Нарушение',\n",
    " 6: 'Перчатка. Нарушение',\n",
    " 7: 'Обувь. Нарушение',\n",
    " 8: 'Одежда. Нарушение',\n",
    " 9: 'Рабочий'}\n",
    "\n",
    "# время кадра\n",
    "def frame_time(milliseconds):\n",
    "  seconds = milliseconds / 1000\n",
    "  minutes, seconds = divmod(seconds, 60)\n",
    "  hours, minutes = divmod(minutes, 60)\n",
    "  return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02}\"\n",
    "\n",
    "# Переводим секунды в кадр\n",
    "def time_to_seconds(time_str, fps=20):\n",
    "  # Разделяем строку на части: часы, минуты и секунды\n",
    "  h, m, s = time_str.split(':')\n",
    "  # Преобразуем каждую часть в целое число\n",
    "  h, m, s = int(h), int(m), int(s)\n",
    "  # Переводим часы, минуты и секунды в секунды\n",
    "  total_seconds = h  *  3600 + m  *  60 + s\n",
    "  # Переводим секунды в кадр\n",
    "  return int(total_seconds*fps)\n",
    "\n",
    "# прогноз по видео\n",
    "def predict(video, step=None, start=None, finish=None):\n",
    "  conf = {}\n",
    "  conf['n_frame'] = list() # порядковый номер кадра в цикле с пропусками\n",
    "  n_frame = 0 # номер первого кадра\n",
    "  conf['CAP_PROP_POS_FRAMES'] = list() # номер кадра из видео\n",
    "  conf['boxes_cls'] = list()  # классы в кадре\n",
    "  conf['batch'] = list() # значение > 0, когда в кадре нарушение\n",
    "  conf['frame_time'] = list() # время кадра\n",
    "\n",
    "  # Open the video file\n",
    "  cap = cv2.VideoCapture(video)\n",
    "\n",
    "  # Get the total number of frames in the video\n",
    "  total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "  # Set the start frame\n",
    "  if start == None:\n",
    "    start = 0\n",
    "  else:\n",
    "    start = time_to_seconds(start, fps=cap.get(cv2.CAP_PROP_FPS))\n",
    "  cap.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "\n",
    "  # Set the last frame\n",
    "  if finish == None:\n",
    "    finish = total_frames\n",
    "  else:\n",
    "    finish = time_to_seconds(finish, fps=cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "  # Step\n",
    "  if step == None:\n",
    "    step = 600\n",
    "\n",
    "  # Loop through the video frames\n",
    "  while cap.isOpened():\n",
    "      # Read a frame from the video\n",
    "      success, frame = cap.read()\n",
    "      if success:\n",
    "          if cap.get(cv2.CAP_PROP_POS_FRAMES) in range(start, finish, step):\n",
    "            # Получить время текущего кадра\n",
    "            conf['frame_time'].append(frame_time(cap.get(cv2.CAP_PROP_POS_MSEC)) )\n",
    "            # номер кадра из видео\n",
    "            conf['CAP_PROP_POS_FRAMES'].append(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "            # порядковый номер кадра в цикле с пропусками\n",
    "            conf['n_frame'].append(n_frame)\n",
    "            n_frame += 1\n",
    "            # Run YOLO inference on the frame\n",
    "            results = model(frame)\n",
    "            # классы на кадр\n",
    "            rbc = results[0].boxes.cls\n",
    "            conf['boxes_cls'].append(dict(Counter([mn[int(i)] for i in sorted(rbc)])))\n",
    "            # серия кадров с классами нарушенений\n",
    "            if len([x for x in rbc if x in [4, 5, 6, 7, 8]]) > 0:\n",
    "              if len(conf['batch']) == 0: conf['batch'].append(1)\n",
    "              else: conf['batch'].append(conf['batch'][-1]+1)\n",
    "            else: conf['batch'].append(0)\n",
    "\n",
    "            # Break the loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "      else:\n",
    "          # Break the loop if the end of the video is reached\n",
    "          break\n",
    "  # Release the video capture object and close the display window\n",
    "  cap.release()\n",
    "  cv2.destroyAllWindows()\n",
    "  return conf\n",
    "\n",
    "# функция возвращает итоговый результат\n",
    "def fr(conf):\n",
    "  frame_range = dict()\n",
    "  frame_range['start'] = list()\n",
    "  frame_range['final'] = list()\n",
    "  frame_range['alert'] = list()\n",
    "\n",
    "  if conf['batch'][0] == 1:\n",
    "    frame_range['start'].append(conf['frame_time'][0])\n",
    "\n",
    "  for x in range(1,len(conf['batch'])):\n",
    "    if conf['batch'][x] == 1:\n",
    "      frame_range['start'].append(conf['frame_time'][x])\n",
    "    if conf['batch'][x] < conf['batch'][x-1]:\n",
    "      frame_range['final'].append(conf['frame_time'][x-1])\n",
    "\n",
    "  if len(frame_range['start']) > len(frame_range['final']):\n",
    "    frame_range['final'].append(conf['frame_time'][-1])\n",
    "\n",
    "  def alerts(i):\n",
    "    start = frame_range['start'][i]\n",
    "    finish = frame_range['final'][i]\n",
    "    lst = []\n",
    "    if start != finish:\n",
    "      for x in conf['boxes_cls'][conf['frame_time'].index(start) : conf['frame_time'].index(finish)]:\n",
    "        lst += x.keys()\n",
    "    if start == finish:\n",
    "      for x in conf['boxes_cls'][conf['frame_time'].index(finish)]:\n",
    "        lst += [x]\n",
    "\n",
    "    lst = np.unique([x for x in lst if x.endswith('Нарушение') or x==\"Курение\"]).tolist()\n",
    "    return ', '.join(lst).replace(\".\", \"\").replace(\" Нарушение\", \"\").lower()\n",
    "\n",
    "  k = 0\n",
    "  for i in range(len(frame_range['start'])):\n",
    "    start_finish = [frame_range[x][i] for x in ['start', 'final']]\n",
    "    frame_range['alert'].append(f'Время {start_finish[0]} - {start_finish[1]}, нарушения: {alerts(i)}.')\n",
    "    k += 1\n",
    "\n",
    "  return frame_range['alert']\n",
    "\n",
    "def video_detection(video, frame_step=None, time_start=None, time_finish=None):\n",
    "  return fr(predict(video, frame_step, time_start, time_finish))  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOJ_BZr_tRQQ"
   },
   "source": [
    "## Симулятор detection.predict последовательности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfqklQ18u7R7"
   },
   "source": [
    "```python\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from collections import Counter\n",
    "\n",
    "# новые названия классов\n",
    "mn = {0: 'Каска',\n",
    " 1: 'Перчатки',\n",
    " 2: 'Обувь',\n",
    " 3: 'Одежда',\n",
    " 4: 'Курение',\n",
    " 5: 'Каска. Нарушение',\n",
    " 6: 'Перчатка. Нарушение',\n",
    " 7: 'Обувь. Нарушение',\n",
    " 8: 'Одежда. Нарушение',\n",
    " 9: 'Рабочий'}\n",
    "\n",
    "def zero(): return list(np.zeros(np.random.randint(1,5), dtype=int))\n",
    "def numbers(): return list(np.arange(1,np.random.randint(2,7)))\n",
    "def c(): return numbers()+zero()\n",
    "\n",
    "# функция возвращает итоговый результат\n",
    "def fr(conf):\n",
    "  frame_range = dict()\n",
    "  frame_range['start'] = list()\n",
    "  frame_range['final'] = list()\n",
    "  frame_range['alert'] = list()\n",
    "\n",
    "  if conf['batch'][0] == 1:\n",
    "    frame_range['start'].append(conf['frame_time'][0])\n",
    "\n",
    "  for x in range(1,len(conf['batch'])):\n",
    "    if conf['batch'][x] == 1:\n",
    "      frame_range['start'].append(conf['frame_time'][x])\n",
    "    if conf['batch'][x] < conf['batch'][x-1]:\n",
    "      frame_range['final'].append(conf['frame_time'][x-1])\n",
    "\n",
    "  if len(frame_range['start']) > len(frame_range['final']):\n",
    "    frame_range['final'].append(conf['frame_time'][-1])\n",
    "\n",
    "  def alerts(i):\n",
    "    start = frame_range['start'][i]\n",
    "    finish = frame_range['final'][i]\n",
    "    lst = []\n",
    "    if start != finish:\n",
    "      for x in conf['boxes_cls'][conf['frame_time'].index(start) : conf['frame_time'].index(finish)]:\n",
    "        lst += x.keys()\n",
    "    if start == finish:\n",
    "      for x in conf['boxes_cls'][conf['frame_time'].index(finish)]:\n",
    "        lst += [x]\n",
    "\n",
    "    lst = np.unique([x for x in lst if x.endswith('Нарушение') or x==\"Курение\"]).tolist()\n",
    "    return ', '.join(lst).replace(\".\", \"\").replace(\" Нарушение\", \"\").lower()\n",
    "\n",
    "  for i in range(len(frame_range['start'])):\n",
    "    start_finish = [frame_range[x][i] for x in ['start', 'final']]\n",
    "    frame_range['alert'].append(f\"Обнаружены нарушения: {alerts(i)}. В промежутках с {start_finish[0]} по {start_finish[1]}.\")\n",
    "\n",
    "  return frame_range['alert']\n",
    "\n",
    "def cls_gen():\n",
    "  return np.random.randint(0,10,np.random.randint(1,10))\n",
    "\n",
    "def boxes_cls(bc):\n",
    "  return (dict(Counter([mn[int(i)] for i in sorted(bc)])))\n",
    "\n",
    "def _frame_time(milliseconds):\n",
    "  seconds = milliseconds / 1000\n",
    "  minutes, seconds = divmod(seconds, 60)\n",
    "  hours, minutes = divmod(minutes, 60)\n",
    "  return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02}\"\n",
    "\n",
    "def data_gen():\n",
    "  l = list()\n",
    "  for x in range(3): l += c()\n",
    "  l += zero()\n",
    "  d = dict()\n",
    "  d['n_frame'] = list(np.arange(len(l)))\n",
    "  k = 10\n",
    "  d['CAP_PROP_POS_FRAMES'] = list(np.arange(0,len(l)*k,k))\n",
    "\n",
    "  classes = [cls_gen() for x in range(len(d['n_frame']))]\n",
    "  d['boxes_cls'] = [boxes_cls(x) for x in classes]\n",
    "\n",
    "  d['batch'] = list()\n",
    "\n",
    "  def _batch(data):\n",
    "    if len([x for x in data if x in [4, 5, 6, 7, 8]]) > 0:\n",
    "      if len(d['batch']) == 0: d['batch'].append(1)\n",
    "      else: d['batch'].append(d['batch'][-1]+1)\n",
    "    else: d['batch'].append(0)\n",
    "\n",
    "  for x in range(len(d['n_frame'])):\n",
    "    _batch(data=classes[x])\n",
    "\n",
    "  d['frame_time'] = [_frame_time(x*135.4) for x in np.arange(1,(len(d['n_frame']))*500,500)]\n",
    "  return d\n",
    "\n",
    "# Генерация detection.predict последовательности\n",
    "d = data_gen()\n",
    "print(d,'\\n')\n",
    "# Итоговый результат\n",
    "fr(d)\n",
    "```\n",
    "```\n",
    "{'n_frame': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18], 'CAP_PROP_POS_FRAMES': [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180], 'boxes_cls': [{'Перчатки': 1, 'Обувь': 1, 'Одежда': 1, 'Каска. Нарушение': 1, 'Перчатка. Нарушение': 3}, {'Одежда': 1, 'Курение': 1, 'Каска. Нарушение': 1, 'Обувь. Нарушение': 1, 'Рабочий': 1}, {'Перчатки': 2, 'Курение': 1}, {'Перчатки': 1, 'Перчатка. Нарушение': 1, 'Обувь. Нарушение': 1, 'Одежда. Нарушение': 1}, {'Каска': 1, 'Обувь': 1, 'Одежда': 1, 'Курение': 1, 'Перчатка. Нарушение': 1, 'Обувь. Нарушение': 3, 'Рабочий': 1}, {'Обувь': 1, 'Курение': 2, 'Перчатка. Нарушение': 1, 'Обувь. Нарушение': 1, 'Рабочий': 1}, {'Каска': 1, 'Обувь. Нарушение': 1}, {'Каска': 3, 'Перчатки': 3, 'Курение': 1}, {'Перчатки': 1, 'Обувь': 1, 'Курение': 1, 'Каска. Нарушение': 1, 'Обувь. Нарушение': 2, 'Одежда. Нарушение': 2, 'Рабочий': 1}, {'Перчатки': 3, 'Одежда': 1, 'Каска. Нарушение': 2, 'Одежда. Нарушение': 1, 'Рабочий': 1}, {'Каска': 1, 'Перчатки': 1, 'Обувь': 1, 'Перчатка. Нарушение': 1, 'Обувь. Нарушение': 1, 'Рабочий': 1}, {'Перчатки': 1, 'Обувь': 1, 'Одежда': 1, 'Курение': 1, 'Перчатка. Нарушение': 1, 'Одежда. Нарушение': 1, 'Рабочий': 1}, {'Курение': 2, 'Одежда. Нарушение': 1, 'Рабочий': 3}, {'Курение': 1, 'Перчатка. Нарушение': 1}, {'Одежда': 1}, {'Одежда': 1, 'Перчатка. Нарушение': 1, 'Одежда. Нарушение': 1, 'Рабочий': 3}, {'Каска': 1, 'Обувь': 2, 'Одежда. Нарушение': 1}, {'Каска': 1}, {'Обувь': 1, 'Обувь. Нарушение': 1}], 'batch': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, 1, 2, 0, 1], 'frame_time': ['00:00:00', '00:01:07', '00:02:15', '00:03:23', '00:04:30', '00:05:38', '00:06:46', '00:07:54', '00:09:01', '00:10:09', '00:11:17', '00:12:24', '00:13:32', '00:14:40', '00:15:47', '00:16:55', '00:18:03', '00:19:11', '00:20:18']}\n",
    "\n",
    "['Обнаружены нарушения: каска, курение, обувь, одежда, перчатка. В промежутках с 00:00:00 по 00:14:40.',\n",
    " 'Обнаружены нарушения: одежда, перчатка. В промежутках с 00:16:55 по 00:18:03.',\n",
    " 'Обнаружены нарушения: обувь. В промежутках с 00:20:18 по 00:20:18.']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfb1fT3ZuSj2"
   },
   "source": [
    "# FAST API\n",
    "\n",
    "Существует большое количество веб-фреймворков, позволяющих это сделать, например, Flask или Django. Однако последние содержат слишком много функций для разработки веб-приложений, которые нам просто не понадобятся (мы не будем работать с веб-страницами, обращаться к базам данных и т.п.).\n",
    "\n",
    "Поэтому воспользуемся специализированным веб-фреймворком, который был разработан специально для создания API - FastAPI.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKLF16vu65Yc"
   },
   "source": [
    "---\n",
    "\n",
    "Внимание!!! Сервер **Uvicorn**, запущенный в Google Colab, не может быть\n",
    "доступен из-за ограничений безопасности.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Чтобы разрешить эту проблему, необходимо создать туннель, который позволит получать доступ к локальному серверу на вашей машине через интернет. Для этого вы можете использовать сервис, такой как ngrok.\n",
    "\n",
    "**Ngrok** - это сервис, который позволяет создавать временные публичные адреса для ваших локальных веб-серверов и туннелировать трафик с помощью безопасного туннеля HTTPS. Это очень полезный инструмент для разработки и отладки веб-приложений, так как он позволяет с легкостью поделиться своим локальным сервером с другими людьми, даже если у вас нет публичного IP-адреса или необходимой настройки маршрутизатора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5f7Q3ORV21N"
   },
   "source": [
    "Создадим новый эндпойнт, который будет принимать файл с изображением и возвращать результат:\n",
    "\n",
    "```\n",
    "!pip -q install ultralytics\n",
    "!pip -q install ffmpeg-python\n",
    "!pip -q install fastapi uvicorn\n",
    "!pip -q install python-multipart\n",
    "!pip -q install ngrok\n",
    "!pip -q install pyngrok\n",
    "```\n",
    "\n",
    "```python\n",
    "%%writefile main.py\n",
    "import uvicorn\n",
    "import cv2\n",
    "import tempfile\n",
    "import os\n",
    "import numpy as np\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "from detection import video_detection\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get('/')\n",
    "def root():\n",
    "    return {'SIZ detection FastAPI': 'Для начала работы перейдите по ссылке http://127.0.0.1:8000/docs'}\n",
    "\n",
    "@app.post(\"/video_detection\")\n",
    "async def predict_video(file: UploadFile = File(...),\n",
    "                        frame_step: int = 600,\n",
    "                        start_time: str = \"00:00:00\",\n",
    "                        stop_time: str = None):\n",
    "    video_bytes = await file.read()\n",
    "    tmp_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "    try:\n",
    "        tmp_file.write(video_bytes)\n",
    "        tmp_file.flush()\n",
    "        p = video_detection(tmp_file.name, frame_step, start_time, stop_time)\n",
    "        \n",
    "        if start_time == \"00:00:00\":\n",
    "          start_time = 'начала'\n",
    "        if stop_time == None:\n",
    "          stop_time = 'конца'\n",
    "        \n",
    "        k = f'{file.filename}, от {start_time} до {stop_time} c шагом кадра {frame_step}.'\n",
    "        return {k: p}\n",
    "    \n",
    "    finally:\n",
    "        tmp_file.close()\n",
    "        os.unlink(tmp_file.name)\n",
    "```\n",
    "```\n",
    "Overwriting main.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEF17r7y6ajV"
   },
   "source": [
    "Логи http-сервера теперь выводятся в файл **nohup.out**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R0jzD_cn88t9",
    "outputId": "71346f7b-6654-4f52-a652-8997776821a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nohup: appending output to 'nohup.out'\n"
     ]
    }
   ],
   "source": [
    "!nohup uvicorn main:app --reload &\n",
    "# nohup и & - прописываются для запуска процесса в фоне (чтобы не блокировать Colab)\n",
    "# параметр --reload позволяет автоматически перезапускать uvicorn при изменениях в файле main.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vz9u7BF9MJs"
   },
   "source": [
    "Эта команда используется для запуска веб-приложения на основе фреймворка **FastAPI** с помощью сервера **uvicorn**\n",
    "\n",
    "* `nohup`: Это утилита в Unix-подобных операционных системах, которая позволяет запустить процесс в фоновом режиме и отключить его от текущего терминала, так что процесс продолжает выполняться, даже если вы выйдете из сеанса или закроете терминал. `nohup` также перенаправляет стандартный вывод и стандартный вывод ошибок в файл `nohup.out`.\n",
    "* `uvicorn`: Это ASGI (Asynchronous Server Gateway Interface) сервер для Python, который позволяет запускать веб-приложения, написанные с использованием ASGI-совместимых фреймворков.\n",
    "* `main:app`: Это аргумент, указывающий, что веб-приложение находится в модуле `main` (обычно файл `main.py`), и его экземпляр называется `app`. Это ожидаемое имя модуля и экземпляра для FastAPI приложений, хотя вы можете использовать другие имена, если у вас есть соответствующая структура проекта\n",
    "* `--reload`: Этот флаг указывает `uvicorn` на перезагрузку приложения каждый раз, когда файлы изменяются. Это полезно во время разработки, так как позволяет автоматически перезапускать сервер, чтобы применить внесенные изменения\n",
    "* `&` помещает процесс в фоновый режим, позволяя вам продолжать работать в командной строке без блокировки ее использования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GVJbK9vt9Moa",
    "outputId": "3084f986-7775-486d-986c-47ce55c7834b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public URL: https://2502-34-125-174-180.ngrok-free.app\n"
     ]
    }
   ],
   "source": [
    "from pyngrok import ngrok\n",
    "\n",
    "ngrok.set_auth_token('2Rqdl2msrROfwvmmnbLNDSfrXz2_uTsrHTPPnHMSjDxwNf2S') # Установите ваш токен аутентификации\n",
    "ngrok.kill()\n",
    "connection = ngrok.connect(8000)\n",
    "print(f\"Public URL: {connection.public_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bqmn86eivpXb"
   },
   "source": [
    "**Request**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCScvcyZ7ySk"
   },
   "source": [
    "**Пример запроса**\n",
    "```\n",
    "import requests\n",
    "\n",
    "url = 'http://localhost:8000/predict'\n",
    "files = {'file': open('test.mp4', 'rb')}\n",
    "params = {'frame_step': 150, 'start_time': '00:00:10', 'stop_time': None}\n",
    "response = requests.post(url, files=files, params=params)\n",
    "print(response)\n",
    "print(response.json())\n",
    "```\n",
    "```\n",
    "<Response [200]>\n",
    "{'test.mp4, от 00:00:10 до конца c шагом кадра 150.': ['Время 00:00:17 - 00:00:24, нарушения: каска, обувь, одежда.']}\n",
    "```\n",
    "\n",
    "**files** - здесь указывается точный адрес до видео файла. Например, `video.mp4`.\n",
    "\n",
    "**url** - локальный адрес для запроса приложения. Менять не желательно.\n",
    "\n",
    "***params***\n",
    "\n",
    "**frame_step:**\n",
    "При `None` будет определено значение 600.\n",
    "Определяет шаг между кадрами для детекции. Влияет на скорость и качество. Если frame_step = 1, то будет детекрирован каждый кадр.\n",
    "\n",
    "- каждый 50 кадр видео: для серъезных вычислительных мощностей.\n",
    "- каждый 200 кадр видео: занимает много времени, сильная детекция. Желательно GPU.\n",
    "- каждый 600 кадр видео: оптимально. Баланс между скоростью и качеством для любых вычислительных мощностей. Детекция каждые 30 секунд видео.\n",
    "- каждый 1200 кадр видео: очень быстро, слабая детекция, для слабых вычислительных мощностей. Например, CPU. Детекция 1 раз в минуту.\n",
    "\n",
    "Значение frame_step не должно превышать, число кадров во всем видео. Однако, получить такую ошибку будет не просто. 1200 кадров при fps 20 - это 1 минута видео.\n",
    "\n",
    "**start_time**\n",
    "При `None` будет определено значение первого кадра, '00:00:00'.\n",
    "Задает время откуда начнется детекция. Например, значение start_time='00:30:00' начнет детекцию видео на тридцатой минуте видео.\n",
    "\n",
    "**stop_time**\n",
    "При `None` будет определено значение последнего кадра.\n",
    "Задает время где закончится детекция. Например, значение stop_time='02:01:30' остановит детекцию видео на втором часу первой минуты и тридцати секунд видео.\n",
    "\n",
    "**Внимание! Параметры не влияют на скорость загрузки видео в приложение.**\n",
    "\n",
    "**requests.post** - алгоритм запроса к приложению.\n",
    "\n",
    "**print(response)**\n",
    "\n",
    "<Response 200> - запрос на URL /predict обрабатывается успешно и возвращает код 200, что указывает на то, что функция /predict работает корректно.\n",
    "\n",
    "<Response 400> - запросы на URL / и /favicon.ico возвращают код 404, что означает, что эти страницы не найдены. Это может быть связано с тем, что вы не настроили обработку этих URL в вашем приложении.\n",
    "\n",
    "Ошибка <Response 500> указывает на внутреннюю ошибку сервера. Возможно, сервер, к которому вы обращаетесь, временно недоступен или возникла ошибка при обработке вашего запроса.\n",
    "Ошибка JSONDecodeError говорит о том, что сервер вернул ответ, который невозможно интерпретировать как корректный JSON. Это может произойти, если сервер вернул неправильный формат данных или ответ вообще не содержит данных.\n",
    "\n",
    "**print(response.json())** - результат работы модели. Возвращает словарь с указанными параметрами и названием видео в ключе и списком всех детектированных нарушений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moxCFYMt6oIa"
   },
   "source": [
    "Сделаем пробный запрос к созданнму эндпойнту (одному из адресов для запросов через API):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inQOOSsBokBo"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import requests\n",
    "\n",
    "url = 'http://localhost:8000/predict'\n",
    "files = {'file': open('test.mp4', 'rb')}\n",
    "params = {'frame_step': 200, 'start_time': None, 'stop_time': None}\n",
    "response = requests.post(url, files=files, params=params)\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6Y_uZh79Yix"
   },
   "source": [
    "Мы используем метод `ngrok.kill()` для принудительного закрытия всех текущих тунелей, поскольку в бесплатной версии ngrok возможно создание только двух тунелей. Попытка создания третьего тунеля приведет к ошибке.\n",
    "\n",
    "После запуска ngrok в Google Colab, вы получите публичный URL, который можно использовать для доступа к вашему FastAPI приложению из интернета.\n",
    "\n",
    "Перейдите по публичному URL, чтобы протестировать свое приложение.\n",
    "\n",
    "Для обращения к маршруту `@app.get(\"/items/{item_id}\")`, вы должны указать значение `item_id` в URL-адресе.\n",
    "\n",
    "Например, если вы запускаете приложение на `https://db6b-35-237-86-171.ngrok.io`, URL-адрес будет выглядеть следующим образом:\n",
    "\n",
    "https://db6b-35-237-86-171.ngrok.io/items/78\n",
    "\n",
    "Чтобы указать параметр q в URL-адресе при обращении к маршруту `@app.get(\"/items/{item_id}\")`, вы можете добавить его после идентификатора элемента, используя символ `?` и затем указать имя параметра и его значение в формате имя=значение.\n",
    "\n",
    "Вот пример URL-адреса с параметром q:\n",
    "\n",
    "https://db6b-35-237-86-171.ngrok.io/items/78?q=example\n",
    "\n",
    "Для завершения всех фоновых процессов можете воспользоваться:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6HVlLfUu9n_u"
   },
   "outputs": [],
   "source": [
    "# завершение всех фоновых процессов\n",
    "!pkill uvicorn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uw25Upg2Br_p"
   },
   "source": [
    "# Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gL3_t5uZBot4"
   },
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM python:3.10.12\n",
    "\n",
    "# Установка конкретных версий библиотек\n",
    "RUN pip install pip==23.1.2\n",
    "\n",
    "RUN apt-get update && apt-get install -y build-essential cmake pkg-config libjpeg-dev libwebp-dev libpng-dev libtiff-dev libopenjp2-7-dev libglib2.0-dev \\\n",
    "    libavcodec-dev libavformat-dev libswscale-dev libv4l-dev libxvidcore-dev libx264-dev \\\n",
    "    libgtk-3-dev libatlas-base-dev gfortran\n",
    "\n",
    "RUN wget -O opencv.zip https://github.com/opencv/opencv/archive/4.8.0.zip\n",
    "RUN unzip opencv.zip\n",
    "RUN mv opencv-4.8.0 opencv\n",
    "\n",
    "RUN pip install ultralytics==8.2.2 Pillow==9.4.0\n",
    "RUN pip install ffmpeg-python==0.2.0 datetime==5.5\n",
    "RUN pip install fastapi==0.110.2 uvicorn==0.29.0\n",
    "RUN pip install python-multipart==0.0.9 ngrok==1.2.0\n",
    "RUN pip install numpy==1.25.2 matplotlib==3.7.1\n",
    "RUN pip install pyngrok==7.1.6 protobuf==3.20.3\n",
    "RUN pip install vidgear==0.3.2\n",
    "\n",
    "# Создание opencv директории\n",
    "WORKDIR /opencv\n",
    "RUN mkdir build\n",
    "WORKDIR /opencv/build\n",
    "RUN cmake -DCMAKE_INSTALL_PREFIX=/usr/local -DBUILD_EXAMPLES=OFF ..\n",
    "RUN make -j$(nproc)\n",
    "RUN make install\n",
    "\n",
    "# Создание рабочей директории\n",
    "WORKDIR /app\n",
    "# Копирование содержимого каталога в директорию приложения\n",
    "COPY detection.py /app/\n",
    "COPY best.pt /app/\n",
    "COPY main.py /app/\n",
    "\n",
    "EXPOSE 8000\n",
    "\n",
    "# Определение команды для запуска приложения внутри контейнера\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "# Флаг --host 0.0.0.0 отвечает за то, чтобы наше веб-приложение работало на всех сетевых интерфейсах контейнера на порту 80.\n",
    "\n",
    "# Дополнительные команды\n",
    "RUN apt-get update && apt-get install -y mesa-common-dev\n",
    "RUN apt-get update && apt-get upgrade -y"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "nihimlEhW-DV",
    "w0thCbl-Wabb",
    "5pizUGe3LOTo",
    "3-s1vP1ILY2G",
    "tOJ_BZr_tRQQ",
    "wfb1fT3ZuSj2"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
